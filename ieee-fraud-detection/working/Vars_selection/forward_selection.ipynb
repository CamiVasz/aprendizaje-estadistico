{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import plot_counts_and_proportion, read_train_transaction, get_categorical_from_df, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "\n",
    "params_tree = {\n",
    "    'application': 'binary',\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'categorical_feature': get_categorical_from_df(X_train)[0],\n",
    "    'learning_rate': learning_rate,\n",
    "    'metric': 'auc',\n",
    "    'min_data': 50,\n",
    "    'max_depth': 10,\n",
    "    'is_unbalance': 'true',\n",
    "    'num_leaves': 31,\n",
    "    # 'feature_fraction': 0.5,\n",
    "    'objective': 'binary',\n",
    "    'sub_feature': .5,\n",
    "    'verbose': 0,\n",
    "}\n",
    "\n",
    "lgb_fit_params = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLGB():\n",
    "    def __init__(self, params_tree, lgb_fit_params):\n",
    "        self.params_tree = params_tree\n",
    "        self.params_iters = lgb_fit_params\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        cats_index = get_categorical_from_df(X)[0]\n",
    "        train_data = lgb.Dataset(X, label=y, categorical_feature=cats_index)\n",
    "        clf = lgb.train(self.params_tree, train_data, **self.params_iters)\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987000     True\n",
       "2987001    False\n",
       "2987002    False\n",
       "2987003    False\n",
       "2987004    False\n",
       "           ...  \n",
       "2991995    False\n",
       "2991996    False\n",
       "2991997    False\n",
       "2991998    False\n",
       "2991999    False\n",
       "Name: card2, Length: 5000, dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionID\n",
      "2987000      NaN\n",
      "2987001    404.0\n",
      "2987002    490.0\n",
      "2987003    567.0\n",
      "2987004    514.0\n",
      "Name: card2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "X, y = read_train_transaction(nrows = 5000,folder_path = '../../input/')\n",
    "print(X.loc[:, col].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionID\n",
      "2987000      NaN\n",
      "2987001    404.0\n",
      "2987002    490.0\n",
      "2987003    567.0\n",
      "2987004    514.0\n",
      "Name: card2, dtype: float64\n",
      "TransactionID\n",
      "2987000    -1\n",
      "2987001   -58\n",
      "2987002    -3\n",
      "2987003    53\n",
      "2987004    14\n",
      "Name: card2, dtype: int8\n"
     ]
    }
   ],
   "source": [
    "X, y = read_train_transaction(nrows = 5000,folder_path = '../../input/')\n",
    "print(X.loc[:, col].head())\n",
    "le = LabelEncoder()\n",
    "\n",
    "col = 'card2'\n",
    "not_nan = ~ X[col].isna() \n",
    "X.loc[not_nan, col] = le.fit_transform(X.loc[not_nan, col])\n",
    "X.loc[~not_nan, col] = -1\n",
    "X.loc[:, col] =  X.loc[:, col].astype('int8')\n",
    "print(X.loc[:, col].head())\n",
    "# le.fit_transform(X['card2'])\n",
    "# sorted(np.unique(le.fit_transform(X['card2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987000     -1.0\n",
       "2987001    198.0\n",
       "2987002    253.0\n",
       "2987003    309.0\n",
       "2987004    270.0\n",
       "           ...  \n",
       "2991995     46.0\n",
       "2991996    142.0\n",
       "2991997    191.0\n",
       "2991998    142.0\n",
       "2991999    300.0\n",
       "Name: card2, Length: 5000, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[:, col].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100., 101., 102., 103., 104., 105., 106., 108., 110., 111., 112.,\n",
       "       113., 114., 115., 117., 118., 122., 123., 126., 127., 128., 130.,\n",
       "       133., 134., 135., 136., 142., 143., 144., 145., 146., 147., 148.,\n",
       "       150., 152., 155., 158., 159., 160., 161., 162., 163., 165., 166.,\n",
       "       167., 168., 170., 171., 172., 174., 176., 177., 180., 181., 183.,\n",
       "       184., 191., 192., 194., 197., 198., 199., 200., 201., 202., 203.,\n",
       "       204., 205., 206., 210., 214., 215., 216., 218., 219., 222., 225.,\n",
       "       226., 229., 231., 234., 236., 239., 240., 242., 243., 245., 246.,\n",
       "       247., 248., 250., 251., 253., 254., 255., 257., 258., 260., 262.,\n",
       "       264., 265., 266., 268., 269., 270., 271., 272., 275., 276., 278.,\n",
       "       280., 281., 283., 284., 285., 286., 287., 290., 291., 294., 295.,\n",
       "       296., 297., 298., 299., 300., 301., 302., 303., 304., 307., 308.,\n",
       "       309., 310., 311., 313., 314., 315., 316., 317., 318., 320., 321.,\n",
       "       322., 324., 325., 327., 330., 332., 333., 336., 337., 339., 340.,\n",
       "       341., 342., 343., 345., 346., 347., 348., 350., 352., 354., 355.,\n",
       "       356., 357., 359., 360., 361., 364., 365., 367., 368., 369., 370.,\n",
       "       371., 372., 373., 374., 375., 376., 381., 382., 383., 384., 385.,\n",
       "       387., 388., 389., 390., 391., 392., 393., 394., 396., 399., 400.,\n",
       "       404., 408., 409., 411., 413., 414., 415., 417., 418., 420., 422.,\n",
       "       423., 424., 426., 428., 429., 431., 432., 433., 435., 437., 439.,\n",
       "       440., 442., 443., 444., 445., 446., 448., 449., 450., 452., 453.,\n",
       "       454., 455., 458., 459., 460., 461., 462., 464., 467., 468., 470.,\n",
       "       472., 474., 475., 476., 477., 478., 479., 480., 481., 485., 489.,\n",
       "       490., 491., 492., 494., 496., 499., 500., 501., 502., 503., 504.,\n",
       "       505., 507., 509., 510., 512., 513., 514., 515., 516., 517., 519.,\n",
       "       520., 523., 525., 527., 528., 529., 530., 532., 533., 534., 535.,\n",
       "       536., 537., 539., 542., 543., 545., 547., 548., 549., 550., 551.,\n",
       "       552., 553., 554., 555., 556., 558., 559., 560., 561., 562., 565.,\n",
       "       566., 567., 568., 569., 570., 571., 572., 574., 578., 579., 581.,\n",
       "       582., 583., 584., 585., 586., 587., 588., 589., 592., 593., 594.,\n",
       "       595., 596., 599., 600.,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f8f529dde287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/lgbm/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    297\u001b[0m                     \"y contains previously unseen labels: %s\" % str(diff))\n\u001b[1;32m    298\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [nan]"
     ]
    }
   ],
   "source": [
    "le.inverse_transform([np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " 'classes_',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'set_params',\n",
       " 'transform']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_train_transaction(nrows = 5000,folder_path = '../../input/')\n",
    "X, y = preprocessing(X, y, detect_outliers=False, convert_DT=False, create_features_props_over_cats = False, group_cat_prop=False,\n",
    "                    is_nan_indicators=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_val_scores(X, y, params_tree, lgb_fit_params, score=roc_auc_score):\n",
    "    score = roc_auc_score\n",
    "    kf = KFold(n_splits=5)\n",
    "    scores = []\n",
    "    for train, test in kf.split(X):\n",
    "        X.iloc[train, :]\n",
    "        X.iloc[test, :]\n",
    "        y.iloc[train]\n",
    "        X_train, X_test, y_train, y_test = X.iloc[train, :], X.iloc[test, :], y.iloc[train], y.iloc[test]\n",
    "        lgb_mod = TrainLGB(params_tree, lgb_fit_params).fit(X_train, y_train)\n",
    "        y_pred = lgb_mod.predict(X_test)\n",
    "        scores.append(score(y_test, y_pred))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8e71825afe9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msubset_predictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mselected_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposs_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_predictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_fit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mbest_augmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposs_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 10)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message='Using categorical_feature in Dataset.')\n",
    "\n",
    "# Forward stepwise selection\n",
    "all_cols = set(X_train.columns)\n",
    "possible_aumentations = set(X_train.columns)\n",
    "selected_vars = []\n",
    "for k in range(len(all_cols)):\n",
    "    # Choose best model among all p-k possible models\n",
    "    best_score = 0\n",
    "    best_augmentation = None\n",
    "    for poss_col in possible_aumentations:\n",
    "        subset_predictors = [*selected_vars, poss_col]\n",
    "        scores = cross_val_scores(X_train[subset_predictors], y, params_tree, lgb_fit_params, roc_auc_score)\n",
    "        if np.mean(scores) > best_score:\n",
    "            best_score = np.mean(scores)\n",
    "            best_augmentation = poss_col\n",
    "    # The best possible augmentation was chosen\n",
    "    selected_vars.append(best_augmentation)\n",
    "    possible_aumentations.remove(best_augmentation)\n",
    "    print(best_augmentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
